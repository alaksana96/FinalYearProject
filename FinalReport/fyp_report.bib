Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Kazemi2014,
abstract = {This paper addresses the problem of Face Alignment for a single image. We show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. We present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. We show how using appropriate priors exploiting the structure of image data helps with ef- ficient feature selection. Different regularization strategies and its importance to combat overfitting are also investi- gated. In addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.},
author = {Kazemi, Vahid and Sullivan, Josephine},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.241},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazemi, Kth - Unknown - One Millisecond Face Alignment with an Ensemble of Regression Trees.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
keywords = {Decision Trees,Face Alignment,Gradient Boosting,Real-Time},
pages = {1867--1874},
title = {{One Millisecond Face Alignment with an Ensemble of Regression Trees}},
url = {https://www.cv-foundation.org/openaccess/content{\_}cvpr{\_}2014/papers/Kazemi{\_}One{\_}Millisecond{\_}Face{\_}2014{\_}CVPR{\_}paper.pdf},
year = {2014}
}
@inproceedings{Piccardi2004,
abstract = {Background subtraction is a widely used approoch for detecting moving objects @om static cameras. Mony different methods have been proposed over the recent years and both the novice and the exprt can be confused about iheir benefits and limitations. In order to overcome this problem, this poper provides a review of ihe main methods and an original categorisotion based on speed, memoy requirements and accuracy, Such o review can effectively guide ihe designer to select the most suitoble meihod for a given application in a principled way. Methods reviewed include parametric and non-porametric background density estimates and spatial correlation approaches.},
author = {Piccardi, Massimo},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piccardi - Unknown - Background subtraction techniques a review.pdf:pdf},
keywords = {background subtraction,moving object detection,parametric and non-parametric approach'zs,spatial correlation},
title = {{Background subtraction techniques: a review*}},
url = {http://profs.sci.univr.it/{~}cristanm/teaching/sar{\_}files/lezione4/Piccardi.pdf},
year = {2004}
}
@inproceedings{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
author = {Dalal, Navneet and Triggs, Bill and Dalal, Navneet and Triggs, Bill},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs - 2005 - Histograms of Oriented Gradients for Human Detection.pdf:pdf},
keywords = {feature extraction,gradient methods,object detec},
pages = {886--893},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {http://lear.inrialpes.fr},
year = {2005}
}
@article{Zeng2017,
abstract = {{\textcopyright} 2017 by the authors. Background subtraction based on change detection is the first step in many computer vision systems. Many background subtraction methods have been proposed to detect foreground objects through background modeling. However, most of these methods are pixel-based, which only use pixel-by-pixel comparisons, and a few others are spatial-based, which take the neighborhood of each analyzed pixel into consideration. In this paper, inspired by a illumination- invariant feature based on locality-sensitive histograms proposed for object tracking, we first develop a novel texture descriptor named the Local Similarity Statistical Descriptor (LSSD), which calculates the similarity between the current pixel and its neighbors. The LSSD descriptor shows good performance in illumination variation and dynamic background scenes. Then, we model each background pixel representation with a combination of color features and LSSD features. These features are then embedded in a low-cost and highly efficient background modeling framework. The color and texture features have their own merits and demerits; they can compensate each other, resulting in better performance. Both quantitative and qualitative evaluations carried out on the change detection dataset are provided to demonstrate the effectiveness of our method.},
author = {Zeng, Dongdong and Zhu, Ming and Zhou, Tongxue and Xu, Fang and Yang, Hang},
doi = {10.3390/app7100989},
file = {:home/aufar/Downloads/fyp{\_}papers/applsci-07-00989-v2.pdf:pdf},
isbn = {8613514499},
journal = {Applied Sciences},
keywords = {background subtraction,descriptor,local similarity statistical,locality-sensitive histograms,video surveillance},
number = {10},
pages = {989},
title = {{Robust Background Subtraction via the Local Similarity Statistical Descriptor}},
url = {https://www.mdpi.com/2076-3417/7/10/989},
volume = {7},
year = {2017}
}
@inproceedings{Girshick2014,
abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30{\%} relative to the previous best result on VOC 2012---achieving a mAP of 53.3{\%}. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/{\~{}}rbg/rcnn.},
archivePrefix = {arXiv},
arxivId = {1311.2524v5},
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.81},
eprint = {1311.2524v5},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girshick et al. - Unknown - Rich feature hierarchies for accurate object detection and semantic segmentation Tech report (v5).pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
pages = {580--587},
title = {{Rich feature hierarchies for accurate object detection and semantic segmentation}},
url = {http://www.cs.berkeley.edu/˜rbg/rcnn.},
year = {2014}
}
@inproceedings{Wojke2018,
abstract = {Simple Online and Realtime Tracking (SORT) is a pragmatic approach to multiple object tracking with a focus on simple, effective algorithms. In this paper, we integrate appearance information to improve the performance of SORT. Due to this extension we are able to track objects through longer periods of occlusions, effectively reducing the number of identity switches. In spirit of the original framework we place much of the computational complexity into an offline pre-training stage where we learn a deep association metric on a large-scale person re-identification dataset. During online application, we establish measurement-to-track associations using nearest neighbor queries in visual appearance space. Experimental evaluation shows that our extensions reduce the number of identity switches by 45{\%}, achieving overall competitive performance at high frame rates.},
archivePrefix = {arXiv},
arxivId = {1703.07402v1},
author = {Wojke, Nicolai and Bewley, Alex and Paulus, Dietrich},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2017.8296962},
eprint = {1703.07402v1},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wojke, Bewley, Paulus - Unknown - SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC(2).pdf:pdf},
isbn = {9781509021758},
issn = {15224880},
keywords = {Computer Vision,Data Association,Multiple Object Tracking},
pages = {3645--3649},
title = {{Simple online and realtime tracking with a deep association metric}},
url = {https://arxiv.org/pdf/1703.07402.pdf},
volume = {2017-Septe},
year = {2018}
}
@techreport{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[6]. The third contribution is a method for combining increasingly more complex classi-fiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differenc-ing or skin color detection.},
author = {Viola, Paul and Jones, Michael},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid Object Detection using a Boosted Cascade of Simple Features.pdf:pdf},
title = {{Rapid Object Detection using a Boosted Cascade of Simple Features}},
url = {https://www.cs.cmu.edu/{~}efros/courses/LBMV07/Papers/viola-cvpr-01.pdf},
year = {2001}
}
@inproceedings{Dicle2013,
abstract = {code},
author = {Dicle, Caglayan and Camps, Octavia I and Sznaier, Mario},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2013.286},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dicle, Camps, Sznaier - 2013 - The Way They Move Tracking Multiple Targets with Similar Appearance.pdf:pdf},
isbn = {9781479928392},
keywords = {Generalized Linear Assignment,Hankel,Multitarget tracking,Rank Estimation,motion dynamics,tracking},
pages = {2304--2311},
title = {{The way they move: Tracking multiple targets with similar appearance}},
url = {http://robustsystems.coe.neu.edu},
year = {2013}
}
@article{Kalman1961,
abstract = {A nonlinear differential equation of the Riccati type is derived for the covariance matrix of the optimal filtering error. The solution of this “variance equation” completely specifies the optimal filter for either finite or infinite smoothing intervals and stationary or nonstationary statistics. The variance equation is closely related to the Hamiltonian (canonical) differential equations of the calculus of variations. Analytic solutions are available in some cases. The significance of the variance equation is illustrated by examples which duplicate, simplify, or extend earlier results in this field. The Duality Principle relating stochastic estimation and deterministic control problems plays an important role in the proof of theoretical results. In several examples, the estimation problem and its dual are discussed side-by-side. Properties of the variance equation are of great interest in the theory of adaptive systems. Some aspects of this are considered briefly.},
author = {Kalman, R. E. and Bucy, R. S.},
doi = {10.1115/1.3658902},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalman, Bucy - 1961 - A New Approach to Linear Filtering and Prediction Problems.pdf:pdf},
issn = {00219223},
journal = {Journal of Basic Engineering},
number = {1},
pages = {95},
title = {{New Results in Linear Filtering and Prediction Theory}},
url = {https://pdfs.semanticscholar.org/5c2f/635fd11d2d001b7f9921007c6d3cf201eebf.pdf http://link.aip.org/link/JBAEAI/v83/i1/p95/s1{\&}Agg=doi http://fluidsengineering.asmedigitalcollection.asme.org/article.aspx?articleid=1430804},
volume = {83},
year = {1961}
}
@article{Murphy-Chutorian2009,
abstract = {The capacity to estimate the head pose of another person is a common human ability that presents a unique challenge for computer vision systems. Compared to face detection and recognition, which have been the primary foci of face-related vision research, identity-invariant head pose estimation has fewer rigorously evaluated systems or generic solutions. In this paper, we discuss the inherent difficulties in head pose estimation and present an organized survey describing the evolution of the field. Our discussion focuses on the advantages and disadvantages of each approach and spans 90 of the most innovative and characteristic papers that have been published on this topic. We compare these systems by focusing on their ability to estimate coarse and fine head pose, highlighting approaches that are well suited for unconstrained environments.},
author = {Murphy-Chutorian, Erik and Trivedi, Mohan Manubhai},
doi = {10.1109/TPAMI.2008.106},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murphy-Chutorian, Manubhai Trivedi - 2008 - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Head Pose Estimation in Com.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Face analysis,Facial landmarks,Gesture analysis,Head pose estimation,Human-computer interfaces},
number = {4},
pages = {607--626},
title = {{Head pose estimation in computer vision: A survey}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.8306{\&}rep=rep1{\&}type=pdf},
volume = {31},
year = {2009}
}
@article{Hou2010,
abstract = {In this paper, our focus is to segment the foreground area for human detection. It is assumed that the foreground region has been detected. Accurate foreground contours are not required. The developed approach adopts a modified ISM (Implicit Shape Model) to collect some typical local patches of human being and their location information. Individuals are detected by grouping some local patches in the foreground area. The method can get good results in crowded scenes. Some examples based on CAVIAR dataset have been shown. A main contribution of the paper is that ISM model and joint occlusion analysis are combined for individual segmentation. There are mainly two advantages: First, with more sufficient information inside the foreground region, even the individuals inside a dense area can also be handled. Secondly, the method does not require an accurate foreground contour. A rough foreground area can be easily obtained in most situations.},
author = {Hou, Ya Li and Pang, Grantham K.H.},
doi = {10.1109/ICIP.2010.5651982},
file = {:home/aufar/Downloads/Human{\_}detection{\_}in{\_}crowded{\_}scenes.pdf:pdf},
isbn = {9781424479948},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Human detection,Implicit shape model,Occlusions},
number = {September 2010},
pages = {721--724},
title = {{Human detection in crowded scenes}},
url = {https://www.researchgate.net/publication/221119054{\_}Human{\_}detection{\_}in{\_}crowded{\_}scenes},
year = {2010}
}
@techreport{Hirabayashi,
abstract = {Vision-based object detection using camera sensors is an essential piece of perception for autonomous vehicles. Various combinations of features and models can be applied to increase the quality and the speed of object detection. A well-known approach uses histograms of oriented gradients (HOG) with deformable models to detect a car in an image [15]. A major challenge of this approach can be found in computational cost introducing a real-time constraint relevant to the real world. In this paper, we present an implementation technique using graphics processing units (GPUs) to accelerate computations of scoring similarity of the input image and the pre-defined models. Our implementation considers the entire program structure as well as the specific algorithm for practical use. We apply the presented technique to the real-world vehicle detection program and demonstrate that our implementation using commodity GPUs can achieve speedups of 3x to 5x in frame-rate over sequential and multithreaded implementations using traditional CPUs.},
author = {Hirabayashi, Manato and Kato, Shinpei and Edahiro, Masato and Takeda, Kazuya and Kawano, Taiki and Mita, Seiichi},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirabayashi et al. - Unknown - GPU Implementations of Object Detection using HOG Features and Deformable Models.pdf:pdf},
keywords = {Computer Vision,Index Terms-GPGPU,Object Detection},
title = {{GPU Implementations of Object Detection using HOG Features and Deformable Models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.709.647{\&}rep=rep1{\&}type=pdf}
}
@inproceedings{Bewley2016,
abstract = {This paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. To this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9{\%}. Despite only using a rudimentary combination of familiar techniques such as the Kalman Filter and Hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to state-of-the-art online trackers. Furthermore, due to the simplicity of our tracking method, the tracker updates at a rate of 260 Hz which is over 20x faster than other state-of-the-art trackers.},
archivePrefix = {arXiv},
arxivId = {1602.00763v2},
author = {Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2016.7533003},
eprint = {1602.00763v2},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bewley et al. - 2017 - SIMPLE ONLINE AND REALTIME TRACKING.pdf:pdf},
isbn = {9781467399616},
issn = {15224880},
keywords = {Computer Vision,Data Association,Detection,Multiple Object Tracking},
pages = {3464--3468},
title = {{Simple online and realtime tracking}},
url = {https://github.com/abewley/sort},
volume = {2016-Augus},
year = {2016}
}
@techreport{Redmon,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon et al. - Unknown - You Only Look Once Unified, Real-Time Object Detection.pdf:pdf},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
url = {http://pjreddie.com/yolo/}
}
