Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@techreport{Redmon,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon et al. - Unknown - You Only Look Once Unified, Real-Time Object Detection.pdf:pdf},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
url = {http://pjreddie.com/yolo/}
}
@article{Hou2010,
abstract = {In this paper, our focus is to segment the foreground area for human detection. It is assumed that the foreground region has been detected. Accurate foreground contours are not required. The developed approach adopts a modified ISM (Implicit Shape Model) to collect some typical local patches of human being and their location information. Individuals are detected by grouping some local patches in the foreground area. The method can get good results in crowded scenes. Some examples based on CAVIAR dataset have been shown. A main contribution of the paper is that ISM model and joint occlusion analysis are combined for individual segmentation. There are mainly two advantages: First, with more sufficient information inside the foreground region, even the individuals inside a dense area can also be handled. Secondly, the method does not require an accurate foreground contour. A rough foreground area can be easily obtained in most situations.},
author = {Hou, Ya Li and Pang, Grantham K.H.},
doi = {10.1109/ICIP.2010.5651982},
file = {:home/aufar/Downloads/Human{\_}detection{\_}in{\_}crowded{\_}scenes.pdf:pdf},
isbn = {9781424479948},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Human detection,Implicit shape model,Occlusions},
number = {September 2010},
pages = {721--724},
title = {{Human detection in crowded scenes}},
url = {https://www.researchgate.net/publication/221119054{\_}Human{\_}detection{\_}in{\_}crowded{\_}scenes},
year = {2010}
}
@techreport{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[6]. The third contribution is a method for combining increasingly more complex classi-fiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differenc-ing or skin color detection.},
author = {Viola, Paul and Jones, Michael},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid Object Detection using a Boosted Cascade of Simple Features.pdf:pdf},
title = {{Rapid Object Detection using a Boosted Cascade of Simple Features}},
url = {https://www.cs.cmu.edu/{~}efros/courses/LBMV07/Papers/viola-cvpr-01.pdf},
year = {2001}
}
@article{Zeng2017,
abstract = {{\textcopyright} 2017 by the authors. Background subtraction based on change detection is the first step in many computer vision systems. Many background subtraction methods have been proposed to detect foreground objects through background modeling. However, most of these methods are pixel-based, which only use pixel-by-pixel comparisons, and a few others are spatial-based, which take the neighborhood of each analyzed pixel into consideration. In this paper, inspired by a illumination- invariant feature based on locality-sensitive histograms proposed for object tracking, we first develop a novel texture descriptor named the Local Similarity Statistical Descriptor (LSSD), which calculates the similarity between the current pixel and its neighbors. The LSSD descriptor shows good performance in illumination variation and dynamic background scenes. Then, we model each background pixel representation with a combination of color features and LSSD features. These features are then embedded in a low-cost and highly efficient background modeling framework. The color and texture features have their own merits and demerits; they can compensate each other, resulting in better performance. Both quantitative and qualitative evaluations carried out on the change detection dataset are provided to demonstrate the effectiveness of our method.},
author = {Zeng, Dongdong and Zhu, Ming and Zhou, Tongxue and Xu, Fang and Yang, Hang},
doi = {10.3390/app7100989},
file = {:home/aufar/Downloads/fyp{\_}papers/applsci-07-00989-v2.pdf:pdf},
isbn = {8613514499},
journal = {Applied Sciences},
keywords = {background subtraction,descriptor,local similarity statistical,locality-sensitive histograms,video surveillance},
number = {10},
pages = {989},
title = {{Robust Background Subtraction via the Local Similarity Statistical Descriptor}},
url = {https://www.mdpi.com/2076-3417/7/10/989},
volume = {7},
year = {2017}
}
@techreport{Hirabayashi,
abstract = {Vision-based object detection using camera sensors is an essential piece of perception for autonomous vehicles. Various combinations of features and models can be applied to increase the quality and the speed of object detection. A well-known approach uses histograms of oriented gradients (HOG) with deformable models to detect a car in an image [15]. A major challenge of this approach can be found in computational cost introducing a real-time constraint relevant to the real world. In this paper, we present an implementation technique using graphics processing units (GPUs) to accelerate computations of scoring similarity of the input image and the pre-defined models. Our implementation considers the entire program structure as well as the specific algorithm for practical use. We apply the presented technique to the real-world vehicle detection program and demonstrate that our implementation using commodity GPUs can achieve speedups of 3x to 5x in frame-rate over sequential and multithreaded implementations using traditional CPUs.},
author = {Hirabayashi, Manato and Kato, Shinpei and Edahiro, Masato and Takeda, Kazuya and Kawano, Taiki and Mita, Seiichi},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirabayashi et al. - Unknown - GPU Implementations of Object Detection using HOG Features and Deformable Models.pdf:pdf},
keywords = {Computer Vision,Index Terms-GPGPU,Object Detection},
title = {{GPU Implementations of Object Detection using HOG Features and Deformable Models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.709.647{\&}rep=rep1{\&}type=pdf}
}
@inproceedings{Piccardi2004,
abstract = {Background subtraction is a widely used approoch for detecting moving objects @om static cameras. Mony different methods have been proposed over the recent years and both the novice and the exprt can be confused about iheir benefits and limitations. In order to overcome this problem, this poper provides a review of ihe main methods and an original categorisotion based on speed, memoy requirements and accuracy, Such o review can effectively guide ihe designer to select the most suitoble meihod for a given application in a principled way. Methods reviewed include parametric and non-porametric background density estimates and spatial correlation approaches.},
author = {Piccardi, Massimo},
file = {:home/aufar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piccardi - Unknown - Background subtraction techniques a review.pdf:pdf},
keywords = {background subtraction,moving object detection,parametric and non-parametric approach'zs,spatial correlation},
title = {{Background subtraction techniques: a review*}},
url = {http://profs.sci.univr.it/{~}cristanm/teaching/sar{\_}files/lezione4/Piccardi.pdf},
year = {2004}
}
