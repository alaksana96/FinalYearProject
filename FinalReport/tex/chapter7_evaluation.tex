\chapter{Evaluation}
This chapter summarises the capabilities of the augmented reality system as a product against the requirement capture, an evaluation of the techniques used to produce the system and the achievements of the project compared to the goals set in the interim report.

\paragraph{}In the interim report, we proposed the "Human Detection System," which would estimate the trajectories of people utilizing a moving object detector. Instead, the final product implements a Human Detection \& Direction system that relies on object detection and body pose estimation. The first and most challenging step of the project was developing the video stream of the front-facing camera on the Hololens. Due to the reliance of the HDD system on the visual input, this made the video stream a critical part of the project. As such, we considered multiple approaches to achieve a real-time stream with a relatively high frame rate. Using Unity, we were able to access the front-facing camera and stream the captured frames to a partner PC. From there, the HDD system can use the YOLO object detector to detect humans in the captured frames and discern the direction they are walking in using the OpenPose pose estimation network and object tracking.  As such, we have achieved the requirements set in Section \ref{sec:reqHDD}. 

\paragraph{}In spite of our achievements, we must be critical of the system we have implemented. Through our development, we found it was challenging to develop a video stream of the front-facing camera due to the limitations of the Unity game engine. We discuss the issues of compression in Section \ref{sec:framerate}, and how it limits the user experience to 5 FPS on the holographic lenses of the Hololens. Despite discussing potential solutions with the members of the PRL and open source contributors online, we were unable to find a realistic solution for faster image compression that could be run outside of the Unity main thread. As such, we had to continue with the project, knowing that there was a limitation on the user experience in terms of holographic stability. Furthermore, due to the limitations of the front facing camera (which captures at 30 FPS), image compression and transfer over the network, we can only achieve a modest 10 FPS on the partner PC. 

\paragraph{}With regards to the person detector in the HDD system, we were able to improve the detections of partially occluded persons and smaller figures at a distance compared to the pre-trained model. We verified this through our visual testing on the MOT dataset and our recorded videos around Imperial College London. On the other hand, we did not end up using the object tracking capabilities of Deep SORT to its full potential. We initially proposed the use of the tracker to determine the directions using only a 2D image by tracking the motions of objects across frames. However, we found this task difficult when the detected person was walking towards or away from the camera, as discussed in Section \ref{sec:objecTrackingDirection}. However, instead of removing the tracker, we kept it in the system for potential future work to increase the hologram stability and better direction estimation.

\paragraph{}Furthermore, the decision to use body pose estimation to determine the direction a person is walking in was an adventurous one. A much simpler option would have been to rely on object tracking and using the depth camera on the Hololens to see how the position of the object changed in the real world. This would have reduced the GPU memory usage, the complexity of the HDD system, and the amount of work required to get the network to run on ROS. In hindsight, we realize it was misguided to rely solely on computer vision techniques to determine the human direction and that a much safer option would have been to utilize the sensors for depth perception available on the Hololens and ARTA.

\paragraph{} Also, in the interim report, we proposed the use of the Pupil Labs eye tracker as a form of wheelchair control. However, streaming the captured video frames caused a limitation in the frame rate of the user experience, and as such, we were unable to implement this goal. We discuss the full reasoning for this in Section \ref{sec:eyeTracker}. We also proposed the development of Hologram warnings using the eye tracker to alert the user on a potential collision. In the final implementation, we have developed hologram visualizations of the directions detected people are walking in which act as a warning for potential collisions. We achieve this through the detections produced by the HDD system and create a map of the detections by utilizing the spatial mapping. Since one of the goals set in the interim report was to control the powered wheelchair using the augmented reality headset, we implemented the reactive control system across ARTA and the Hololens. However, from our testing, we found that there are several issues with the reactive control system, and most of them stem from the fact that we are using a single video input as our source of decision making.

\paragraph{}From our results, we realize that the combination of a low frame rate from the video stream and the network delay during transfer between the Hololens and partner PC results in latency between the processed frame and current view of the PWU. This latency also results in incorrect projections of image pixels to world coordinate space. As discussed in Section \ref{sec:fullSystemTest}, this causes holograms to jitter in position, as well as affecting the output of the reactive control system velocity. To avoid the issue of inaccurate hologram placement in the world, a solution would have been to use Spatial Anchors and placing holograms relative to the anchors. This would also increase the accuracy of the hologram in the real world relative to the virtual world rendered by the Hololens. However, we did not use spatial anchors because one of the ideas for this system is for PWU to be able to wear it in the streets, in unmapped places where spatial anchors are not already placed. 

\paragraph{}Finally, we discuss the reactive control system, which we implement on the Hololens and ARTA. The system relies solely on the mapping of detected people created by the Unity application. However, we found that this results in a system that can be unstable, depending on the accuracy of the detections. From our tests, we also noticed that the lighting of the room affected the systems ability to detect people, due to the resolution of the front-facing camera. As such, a better approach for collision avoidance would have been to utilize the PRL developed obstacle avoidance ROS packages built for ARTA. These libraries would have made the development of the reactive control system much simpler. Furthermore, from our tests, we also noticed that the wheelchair would reduce its velocity rapidly when detecting an object moving towards it. This is due to the choice of scaling function, which are much too aggressive for real-world use. Instead, a smoother scaling function that reduces the velocity slowly is more suitable for a powered wheelchair, resulting in a smoother ride.
