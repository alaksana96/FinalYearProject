# Personal Robotics Lab Research Notes

## Research Areas
[Link](https://www.imperial.ac.uk/personal-robotics/research/)  

### Hierarchial Task Representation and Machine Learning
When you observe a person performing an action, there are multiple levels of abstraction that you can use to describe what they are doing. You can describe the trajectories of their body parts, the objects they are using, and/or the effects they are having on their environment. Additionally, if you observe them long enough, you might notice particular usage patterns, traits, and preferences. We are performing research in algorithms for learning task representations that accommodate these abstraction levels. Our published work includes representations at the trajectory level using statistical methods (including gaussian processes, quantum statistics, Dirichlet processes, among others), neural networks (including reservoir computing algorithms), and linguistic approaches (for example stochastic context free grammars).

### In-Vehicle Intelligent Systems
We design and implement algorithms for modelling the user's behaviour during driving. Our aim is to provide personal assistance and training as well as predict and avoid forthcoming critical situations.

[Personalised Training In Driving](https://www.imperial.ac.uk/personal-robotics/research/personalised_training_driving/)

[Driver Intent Prediction](https://www.imperial.ac.uk/personal-robotics/research/driver-intent-prediction/)

### Robot Vision
Building kinematic structures of articulated objects from visual input data is an active research topic in computer vision and robotics. The accurately estimated kinematic structure represents motion properties as well as shape information of an object in a topological manner, and it encodes relationships between rigid body parts connected by kinematic joints.

Accurate and efficient estimation of kinematic correspondences between heterogeneous objects is beneficial in the computer vision and robotic fields for many high level tasks such as learning by imitation, human motion retargeting to robots, human action recognition from different sensors, viewpoint invariant human action recognition by 3D skeletons, behaviour discovery and alignment, affordance based object/tool categorisation, body scheme learning for robotic manipulators, and articulated object manipulation. Therefore, in our lab we focus on estimating accurate kinematic structures and finding correspondences between two articulated kinematic structures extracted from different objects.